
% Journals

% First the Full Name is given, then the abbreviation used in the AMS Math
% Reviews, with an indication if it could not be found there.
% Note the 2nd overwrites the 1st, so swap them if you want the full name.

 %{AMS}
 @String{AMSTrans = "American Mathematical Society Translations" }
 @String{AMSTrans = "Amer. Math. Soc. Transl." }
 @String{BullAMS = "Bulletin of the American Mathematical Society" }
 @String{BullAMS = "Bull. Amer. Math. Soc." }
 @String{ProcAMS = "Proceedings of the American Mathematical Society" }
 @String{ProcAMS = "Proc. Amer. Math. Soc." }
 @String{TransAMS = "Transactions of the American Mathematical Society" }
 @String{TransAMS = "Trans. Amer. Math. Soc." }

 %ACM
 @String{CACM = "Communications of the {ACM}" }
 @String{CACM = "Commun. {ACM}" }
 @String{CompServ = "Comput. Surveys" }
 @String{JACM = "J. ACM" }
 @String{ACMMathSoft = "{ACM} Transactions on Mathematical Software" }
 @String{ACMMathSoft = "{ACM} Trans. Math. Software" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newsletter" }
 @String{SIGNUM = "{ACM} {SIGNUM} Newslett." }

 @String{AmerSocio = "American Journal of Sociology" }
 @String{AmerStatAssoc = "Journal of the American Statistical Association" }
 @String{AmerStatAssoc = "J. Amer. Statist. Assoc." }
 @String{ApplMathComp = "Applied Mathematics and Computation" }
 @String{ApplMathComp = "Appl. Math. Comput." }
 @String{AmerMathMonthly = "American Mathematical Monthly" }
 @String{AmerMathMonthly = "Amer. Math. Monthly" }
 @String{BIT = "{BIT}" }
 @String{BritStatPsych = "British Journal of Mathematical and Statistical
          Psychology" }
 @String{BritStatPsych = "Brit. J. Math. Statist. Psych." }
 @String{CanMathBull = "Canadian Mathematical Bulletin" }
 @String{CanMathBull = "Canad. Math. Bull." }
 @String{CompApplMath = "Journal of Computational and Applied Mathematics" }
 @String{CompApplMath = "J. Comput. Appl. Math." }
 @String{CompPhys = "Journal of Computational Physics" }
 @String{CompPhys = "J. Comput. Phys." }
 @String{CompStruct = "Computers and Structures" }
 @String{CompStruct = "Comput. \& Structures" }
 @String{CompJour = "The Computer Journal" }
 @String{CompJour = "Comput. J." }
 @String{CompSysSci = "Journal of Computer and System Sciences" }
 @String{CompSysSci = "J. Comput. System Sci." }
 @String{Computing = "Computing" }
 @String{ContempMath = "Contemporary Mathematics" }
 @String{ContempMath = "Contemp. Math." }
 @String{Crelle = "Crelle's Journal" }
 @String{GiornaleMath = "Giornale di Mathematiche" }
 @String{GiornaleMath = "Giorn. Mat." } % didn't find in AMS MR., ibid.

 %IEEE
 @String{Computer = "{IEEE} Computer" }
 @String{IEEETransComp = "{IEEE} Transactions on Computers" }
 @String{IEEETransComp = "{IEEE} Trans. Comput." }
 @String{IEEETransAC = "{IEEE} Transactions on Automatic Control" }
 @String{IEEETransAC = "{IEEE} Trans. Automat. Control" }
 @String{IEEESpec = "{IEEE} Spectrum" } % didn't find in AMS MR
 @String{ProcIEEE = "Proceedings of the {IEEE}" }
 @String{ProcIEEE = "Proc. {IEEE}" } % didn't find in AMS MR
 @String{IEEETransAeroElec = "{IEEE} Transactions on Aerospace and Electronic
     Systems" }
 @String{IEEETransAeroElec = "{IEEE} Trans. Aerospace Electron. Systems" }

 @String{IMANumerAna = "{IMA} Journal of Numerical Analysis" }
 @String{IMANumerAna = "{IMA} J. Numer. Anal." }
 @String{InfProcLet = "Information Processing Letters" }
 @String{InfProcLet = "Inform. Process. Lett." }
 @String{InstMathApp = "Journal of the Institute of Mathematics and
     its Applications" }
 @String{InstMathApp = "J. Inst. Math. Appl." }
 @String{IntControl = "International Journal of Control" }
 @String{IntControl = "Internat. J. Control" }
 @String{IntNumerEng = "International Journal for Numerical Methods in
     Engineering" }
 @String{IntNumerEng = "Internat. J. Numer. Methods Engrg." }
 @String{IntSuper = "International Journal of Supercomputing Applications" }
 @String{IntSuper = "Internat. J. Supercomputing Applic." } % didn't find
%% in AMS MR
 @String{Kibernetika = "Kibernetika" }
 @String{JResNatBurStand = "Journal of Research of the National Bureau
     of Standards" }
 @String{JResNatBurStand = "J. Res. Nat. Bur. Standards" }
 @String{LinAlgApp = "Linear Algebra and its Applications" }
 @String{LinAlgApp = "Linear Algebra Appl." }
 @String{MathAnaAppl = "Journal of Mathematical Analysis and Applications" }
 @String{MathAnaAppl = "J. Math. Anal. Appl." }
 @String{MathAnnalen = "Mathematische Annalen" }
 @String{MathAnnalen = "Math. Ann." }
 @String{MathPhys = "Journal of Mathematical Physics" }
 @String{MathPhys = "J. Math. Phys." }
 @String{MathComp = "Mathematics of Computation" }
 @String{MathComp = "Math. Comp." }
 @String{MathScand = "Mathematica Scandinavica" }
 @String{MathScand = "Math. Scand." }
 @String{TablesAidsComp = "Mathematical Tables and Other Aids to Computation" }
 @String{TablesAidsComp = "Math. Tables Aids Comput." }
 @String{NumerMath = "Numerische Mathematik" }
 @String{NumerMath = "Numer. Math." }
 @String{PacificMath = "Pacific Journal of Mathematics" }
 @String{PacificMath = "Pacific J. Math." }
 @String{ParDistComp = "Journal of Parallel and Distributed Computing" }
 @String{ParDistComp = "J. Parallel and Distrib. Comput." } % didn't find
%% in AMS MR
 @String{ParComputing = "Parallel Computing" }
 @String{ParComputing = "Parallel Comput." }
 @String{PhilMag = "Philosophical Magazine" }
 @String{PhilMag = "Philos. Mag." }
 @String{ProcNAS = "Proceedings of the National Academy of Sciences
                    of the USA" }
 @String{ProcNAS = "Proc. Nat. Acad. Sci. U. S. A." }
 @String{Psychometrika = "Psychometrika" }
 @String{QuartMath = "Quarterly Journal of Mathematics, Oxford, Series (2)" }
 @String{QuartMath = "Quart. J. Math. Oxford Ser. (2)" }
 @String{QuartApplMath = "Quarterly of Applied Mathematics" }
 @String{QuartApplMath = "Quart. Appl. Math." }
 @String{RevueInstStat = "Review of the International Statisical Institute" }
 @String{RevueInstStat = "Rev. Inst. Internat. Statist." }

 %SIAM
 @String{JSIAM = "Journal of the Society for Industrial and Applied
     Mathematics" }
 @String{JSIAM = "J. Soc. Indust. Appl. Math." }
 @String{JSIAMB = "Journal of the Society for Industrial and Applied
     Mathematics, Series B, Numerical Analysis" }
 @String{JSIAMB = "J. Soc. Indust. Appl. Math. Ser. B Numer. Anal." }
 @String{SIAMAlgMeth = "{SIAM} Journal on Algebraic and Discrete Methods" }
 @String{SIAMAlgMeth = "{SIAM} J. Algebraic Discrete Methods" }
 @String{SIAMAppMath = "{SIAM} Journal on Applied Mathematics" }
 @String{SIAMAppMath = "{SIAM} J. Appl. Math." }
 @String{SIAMComp = "{SIAM} Journal on Computing" }
 @String{SIAMComp = "{SIAM} J. Comput." }
 @String{SIAMMatrix = "{SIAM} Journal on Matrix Analysis and Applications" }
 @String{SIAMMatrix = "{SIAM} J. Matrix Anal. Appl." }
 @String{SIAMNumAnal = "{SIAM} Journal on Numerical Analysis" }
 @String{SIAMNumAnal = "{SIAM} J. Numer. Anal." }
 @String{SIAMReview = "{SIAM} Review" }
 @String{SIAMReview = "{SIAM} Rev." }
 @String{SIAMSciStat = "{SIAM} Journal on Scientific and Statistical
     Computing" }
 @String{SIAMSciStat = "{SIAM} J. Sci. Statist. Comput." }

 @String{SoftPracExp = "Software Practice and Experience" }
 @String{SoftPracExp = "Software Prac. Experience" } % didn't find in AMS MR
 @String{StatScience = "Statistical Science" }
 @String{StatScience = "Statist. Sci." }
 @String{Techno = "Technometrics" }
 @String{USSRCompMathPhys = "{USSR} Computational Mathematics and Mathematical
     Physics" }
 @String{USSRCompMathPhys = "{U. S. S. R.} Comput. Math. and Math. Phys." }
 @String{VLSICompSys = "Journal of {VLSI} and Computer Systems" }
 @String{VLSICompSys = "J. {VLSI} Comput. Syst." }
 @String{ZAngewMathMech = "Zeitschrift fur Angewandte Mathematik und
     Mechanik" }
 @String{ZAngewMathMech = "Z. Angew. Math. Mech." }
 @String{ZAngewMathPhys = "Zeitschrift fur Angewandte Mathematik und Physik" }
 @String{ZAngewMathPhys = "Z. Angew. Math. Phys." }

% Publishers % ================================================= |

 @String{Academic = "Academic Press" }
 @String{ACMPress = "{ACM} Press" }
 @String{AdamHilger = "Adam Hilger" }
 @String{AddisonWesley = "Addison-Wesley" }
 @String{AllynBacon = "Allyn and Bacon" }
 @String{AMS = "American Mathematical Society" }
 @String{Birkhauser = "Birkha{\"u}ser" }
 @String{CambridgePress = "Cambridge University Press" }
 @String{Chelsea = "Chelsea" }
 @String{ClaredonPress = "Claredon Press" }
 @String{DoverPub = "Dover Publications" }
 @String{Eyolles = "Eyolles" }
 @String{HoltRinehartWinston = "Holt, Rinehart and Winston" }
 @String{Interscience = "Interscience" }
 @String{JohnsHopkinsPress = "The Johns Hopkins University Press" }
 @String{JohnWileySons = "John Wiley and Sons" }
 @String{Macmillan = "Macmillan" }
 @String{MathWorks = "The Math Works Inc." }
 @String{McGrawHill = "McGraw-Hill" }
 @String{NatBurStd = "National Bureau of Standards" }
 @String{NorthHolland = "North-Holland" }
 @String{OxfordPress = "Oxford University Press" }  %address Oxford or London?
 @String{PergamonPress = "Pergamon Press" }
 @String{PlenumPress = "Plenum Press" }
 @String{PrenticeHall = "Prentice-Hall" }
 @String{SIAMPub = "{SIAM} Publications" }
 @String{Springer = "Springer-Verlag" }
 @String{TexasPress = "University of Texas Press" }
 @String{VanNostrand = "Van Nostrand" }
 @String{WHFreeman = "W. H. Freeman and Co." }

%Entries

%example entry
@book{RN137,
   author = {Kahneman, Daniel},
   title = {Thinking, fast and slow},
   publisher = {Farrar, Straus and Giroux},
   address = {New York, NY, US},
   series = {Thinking, fast and slow.},
   abstract = {In the highly anticipated Thinking, Fast and Slow, Kahneman takes us on a groundbreaking tour of the mind and explains the two systems that drive the way we think. System 1 is fast, intuitive, and emotional; System 2 is slower, more deliberative, and more logical. Kahneman exposes the extraordinary capabilities—and also the faults and biases—of fast thinking, and reveals the pervasive influence of intuitive impressions on our thoughts and behavior. The impact of loss aversion and overconfidence on corporate strategies, the difficulties of predicting what will make us happy in the future, the challenges of properly framing risks at work and at home, the profound effect of cognitive biases on everything from playing the stock market to planning the next vacation—each of these can be understood only by knowing how the two systems shape our judgments and decisions. Engaging the reader in a lively conversation about how we think, Kahneman reveals where we can and cannot trust our intuitions and how we can tap into the benefits of slow thinking. He offers practical and enlightening insights into how choices are made in both our business and our personal lives—and how we can use different techniques to guard against the mental glitches that often get us into trouble. Thinking, Fast and Slow will transform the way you think about thinking. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
   keywords = {*Cognitive Processes
*Mind
*Thinking
Choice Behavior
Decision Making
Intuition
Judgment},
   pages = {499-499},
   ISBN = {0-374-27563-7 (Hardcover); 1-4299-6935-0 (PDF); 978-0-374-27563-1 (Hardcover); 978-1-4299-6935-2 (PDF)},
   year = {2011},
   type = {Book}
}

@article{RN96,
   author = {Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy},
   title = {SQuAD: 100,000+ Questions for Machine Comprehension of Text},
   journal = {Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing},
   year = {2016},
   type = {Journal Article}
}

@misc{RN89,
   author = {Dhingra, Bhuwan and Liu, Hanxiao and Yang, Zhilin and Cohen, William and Salakhutdinov, Ruslan},
   title = {Gated-Attention Readers for Text Comprehension},
   pages = {1832-1846},
   DOI = {10.18653/v1/P17-1168},
   year = {2017},
   type = {Conference Paper}
}

@article{RN6,
   author = {Gilmer, Justin and Schoenholz, Samuel S. and Riley, Patrick F. and Vinyals, Oriol and Dahl, George E.},
   title = {Neural Message Passing for Quantum Chemistry},
   year = {2017},
   type = {Journal Article}
}

@inproceedings{RN125,
   author = {Joshi, Mandar and Choi, Eunsol and Weld, Daniel and Zettlemoyer, Luke},
   title = {TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for
            Reading Comprehension},
   year = {2017},
   booktitle = {Proceedings of the 55th Annual Meeting of the Association for
          Computational Linguistics (Volume 1: Long Papers)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p17-1147},
   type = {Conference Proceedings}
}

@article{RN2,
   author = {Kipf, Thomas N. and Welling, Max},
   title = {Semi-Supervised Classification with Graph Convolutional Networks},
   journal = {ICLR 2017},
   year = {2017},
   type = {Journal Article}
}

@misc{RN79,
   author = {Shen, Yelong and Huang, Po-Sen and Gao, Jianfeng and Chen, Weizhu},
   title = {ReasoNet},
   pages = {1047-1055},
   DOI = {10.1145/3097983.3098177},
   year = {2017},
   type = {Conference Paper}
}

@article{RN88,
   author = {Dhingra, Bhuwan and Jin, Qiao and Yang, Zhilin and Cohen, William and Salakhutdinov, Ruslan},
   title = {Neural Models for Reasoning over Multiple Mentions Using Coreference},
   volume = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers)},
   year = {2018},
   type = {Journal Article}
}

@article{RN139,
   author = {Kočiský, Tomáš and Schwarz, Jonathan and Blunsom, Phil and Dyer, Chris and Hermann, Karl Moritz and Melis, Gábor and Grefenstette, Edward},
   title = {The NarrativeQA Reading Comprehension Challenge},
   journal = {Transactions of the Association for Computational Linguistics},
   volume = {6},
   pages = {317-328},
   ISSN = {2307-387X},
   DOI = {10.1162/tacl_a_00023},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN121,
   author = {Mihaylov, Todor and Clark, Peter and Khot, Tushar and Sabharwal, Ashish},
   title = {Can a Suit of Armor Conduct Electricity? A New Dataset for Open Book Question Answering},
   booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/d18-1260},
   type = {Conference Proceedings}
}

@inbook{RN148,
   author = {Schlichtkrull, Michael and Kipf, Thomas N. and Bloem, Peter and Den Berg, Van, Rianne and Titov, Ivan and Welling, Max},
   title = {Modeling Relational Data with Graph Convolutional Networks},
   booktitle = {The Semantic Web},
   publisher = {Springer International Publishing},
   pages = {593-607},
   ISBN = {0302-9743},
   DOI = {10.1007/978-3-319-93417-4_38},
   url = {http://arxiv.org/pdf/1703.06103},
   year = {2018},
   type = {Book Section}
}

@article{RN81,
   author = {Song, Linfeng and Wang, Zhiguo and Yu, Mo and Zhang, Yue and Florian, Radu and Gildea, Daniel},
   title = {Exploring Graph-structured Passage Representation for Multi-hop Reading Comprehension with Graph Neural Networks},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN104,
   author = {Talmor, Alon and Berant, Jonathan},
   title = {The Web as a Knowledge-Base for Answering Complex Questions},
   booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
          the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   year = {2018},
   DOI = {10.18653/v1/n18-1059},
   type = {Conference Proceedings}
}

@article{RN7,
   author = {Veličković, Petar and Cucurull, Guillem and Casanova, Arantxa and Romero, Adriana and Liò, Pietro and Bengio, Yoshua},
   title = {Graph Attention Networks},
   year = {2018},
   type = {Journal Article}
}

@article{RN115,
   author = {Welbl, Johannes and Stenetorp, Pontus and Riedel, Sebastian},
   title = {Constructing Datasets for Multi-hop Reading Comprehension Across Documents},
   journal = {Transactions of the Association for Computational Linguistics},
   volume = {6},
   pages = {287-302},
   ISSN = {2307-387X},
   DOI = {10.1162/tacl_a_00021},
   year = {2018},
   type = {Journal Article}
}

@article{RN15,
   author = {Xu, Keyulu and Hu, Weihua and Leskovec, J. and Jegelka, S.},
   title = {How Powerful are Graph Neural Networks?},
   year = {2018},
   type = {Journal Article}
}

@inproceedings{RN116,
   author = {Yang, Zhilin and Qi, Peng and Zhang, Saizheng and Bengio, Yoshua and Cohen, William and Salakhutdinov, Ruslan and Manning, Christopher D.},
   title = {HotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering},
   booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
   publisher = {Association for Computational Linguistics},
   pages = {2369–2380},
   year = {2018},
   DOI = {10.18653/v1/d18-1259},
   type = {Conference Proceedings}
}

@inproceedings{RN141,
   author = {Cao, Yu and Fang, Meng and Tao, Dacheng},
   title = {BAG: Bi-directional attention entity graph convolutional network for multi-hop reasoning question answering},
   year = {2019},
   booktitle = {Proceedings of the 2019 Conference of the North},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/n19-1032},
   type = {Conference Proceedings}
}

@inproceedings{RN117,
   author = {De Cao, Nicola and Aziz, Wilker and Titov, Ivan},
   title = {Question Answering by Reasoning Across Documents with Graph Convolutional Networks},
   year = {2019},
   booktitle = {Proceedings of the 2019 Conference of the North},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/n19-1240},
   type = {Conference Proceedings}
}

@inproceedings{RN118,
   author = {Ding, Ming and Zhou, Chang and Chen, Qibin and Yang, Hongxia and Tang, Jie},
   title = {Cognitive Graph for Multi-Hop Reading Comprehension at Scale},
   year = {2019},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1259},
   type = {Conference Proceedings}
}

@inproceedings{RN140,
   author = {Jiang, Yichen and Bansal, Mohit},
   title = {Self-Assembling Modular Networks for Interpretable Multi-Hop Reasoning},
   booktitle = {Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/d19-1455},
   type = {Conference Proceedings}
}

@inproceedings{RN120,
   author = {Kundu, Souvik and Khot, Tushar and Sabharwal, Ashish and Clark, Peter},
   title = {Exploiting Explicit Paths for Multi-hop Reading Comprehension},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1263},
   type = {Conference Proceedings}
}

@inproceedings{RN150,
   author = {Min, Sewon and Wallace, Eric and Singh, Sameer and Gardner, Matt and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
   title = {Compositional Questions Do Not Necessitate Multi-hop Reasoning},
   year = {2019},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1416},
   type = {Conference Proceedings}
}

@inproceedings{RN122,
   author = {Qiu, Lin and Xiao, Yunxuan and Qu, Yanru and Zhou, Hao and Li, Lei and Zhang, Weinan and Yu, Yong},
   title = {Dynamically Fused Graph Network for Multi-hop Reasoning},
   year = {2019},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1617},
   type = {Conference Proceedings}
}

@inproceedings{RN124,
   author = {Tu, Ming and Wang, Guangtao and Huang, Jing and Tang, Yun and He, Xiaodong and Zhou, Bowen},
   title = {Multi-hop Reading Comprehension across Multiple Documents by Reasoning over Heterogeneous Graphs},
   year = {2019},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1260},
   type = {Conference Proceedings}
}

@misc{RN123,
   author = {Zhong, Victor and Xiong, Caiming and Shirish Keskar, Nitish and Socher, Richard},
   title = {Coarse-grain Fine-grain Coattention Network for Multi-evidence Question Answering},
   pages = {arXiv:1901.00603},
   month = {January 01, 2019},
   note = {ICLR 2019; 9 pages, 7 figures},
   abstract = {End-to-end neural models have made significant progress in question answering, however recent studies show that these models implicitly assume that the answer and evidence appear close together in a single document. In this work, we propose the Coarse-grain Fine-grain Coattention Network (CFC), a new question answering model that combines information from evidence across multiple documents. The CFC consists of a coarse-grain module that interprets documents with respect to the query then finds a relevant answer, and a fine-grain module which scores each candidate answer by comparing its occurrences across all of the documents with the query. We design these modules using hierarchies of coattention and self-attention, which learn to emphasize different parts of the input. On the Qangaroo WikiHop multi-evidence question answering task, the CFC obtains a new state-of-the-art result of 70.6% on the blind test set, outperforming the previous best by 3% accuracy despite not using pretrained contextual encoders.},
   keywords = {Computer Science - Computation and Language
Computer Science -
Artificial Intelligence},
   DOI = {10.48550/arXiv.1901.00603},
   url = {https://ui.adsabs.harvard.edu/abs/2019arXiv190100603Z},
   year = {2019},
   type = {Electronic Article}
}

@article{RN145,
   author = {Beltagy, Iz and Peters, Matthew E. and Cohan, Arman},
   title = {Longformer: The Long-Document Transformer},
   journal = {ArXiv},
   volume = {abs/2004.05150},
   url = {https://api.semanticscholar.org/CorpusID:215737171 },
   year = {2020},
   type = {Journal Article}
}

@article{RN54,
   author = {Chen, Yu and Wu, Lingfei and Zaki, Mohammed J.},
   title = {GraphFlow: Exploiting Conversation Flow with Graph Neural Networks for Conversational Machine Comprehension},
   journal = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{RN119,
   author = {Fang, Yuwei and Sun, Siqi and Gan, Zhe and Pillai, Rohit and Wang, Shuohang and Liu, Jingjing},
   title = {Hierarchical Graph Network for Multi-hop Question Answering},
   year = {2020},
   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.emnlp-main.710},
   type = {Conference Proceedings}
}

@inproceedings{RN126,
   author = {Groeneveld, Dirk and Khot, Tushar and Mausam and Sabharwal, Ashish},
   title = {A Simple Yet Strong Pipeline for HotpotQA},
   year = {2020},
   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.emnlp-main.711},
   type = {Conference Proceedings}
}

@inbook{RN142,
   author = {Li, Xiaohui and Liu, Yuezhong and Ju, Shenggen and Xie, Zhengwen},
   title = {Dynamic Reasoning Network for Multi-hop Question Answering},
   booktitle = {Natural Language Processing and Chinese Computing},
   publisher = {Springer International Publishing},
   pages = {29-40},
   ISBN = {0302-9743},
   DOI = {10.1007/978-3-030-60450-9_3},
   year = {2020},
   type = {Book Section}
}

@inproceedings{RN127,
   author = {Shao, Nan and Cui, Yiming and Liu, Ting and Wang, Shijin and Hu, Guoping},
   title = {Is Graph Structure Necessary for Multi-hop Question Answering?},
   year = {2020},
   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.emnlp-main.583},
   type = {Conference Proceedings}
}

@article{RN91,
   author = {Tang, Zeyun and Shen, Yongliang and Ma, Xinyin and Xu, Wei and Yu, Jiale and Lu, Weiming},
   title = {Multi-hop Reading Comprehension across Documents with Path-based Graph Convolutional Network},
   journal = {Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence},
   volume = {Main track. Pages 3905-3911. https://doi.org/10.24963/ijcai.2020/540},
   year = {2020},
   type = {Journal Article}
}

@article{RN114,
   author = {Tu, Ming and Huang, Kevin and Wang, Guangtao and Huang, Jing and He, Xiaodong and Zhou, Bowen},
   title = {Select, Answer and Explain: Interpretable Multi-Hop Reading Comprehension over Multiple Documents},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {34},
   number = {05},
   pages = {9073-9080},
   ISSN = {2374-3468},
   DOI = {10.1609/aaai.v34i05.6441},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{RN128,
   author = {Wang, Danqing and Liu, Pengfei and Zheng, Yining and Qiu, Xipeng and Huang, Xuanjing},
   title = {Heterogeneous Graph Neural Networks for Extractive Document Summarization},
   booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.acl-main.553},
   type = {Conference Proceedings}
}

@article{RN129,
   author = {Zeng, Changchang and Li, Shaobo and Li, Qin and Hu, Jie and Hu, Jianjun},
   title = {A Survey on Machine Reading Comprehension—Tasks, Evaluation Metrics and Benchmark Datasets},
   journal = {Applied Sciences},
   volume = {10},
   number = {21},
   pages = {7640},
   ISSN = {2076-3417},
   DOI = {10.3390/app10217640},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{RN130,
   author = {Zheng, Bo and Wen, Haoyang and Liang, Yaobo and Duan, Nan and Che, Wanxiang and Jiang, Daxin and Zhou, Ming and Liu, Ting},
   title = {Document Modeling with Graph Attention Networks for Multi-grained Machine Reading Comprehension},
   year = {2020},
   booktitle = {Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.acl-main.599},
   type = {Conference Proceedings}
}

@article{RN1,
   author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
   title = {Graph neural networks: A review of methods and applications},
   journal = {AI Open},
   volume = {1},
   pages = {57-81},
   ISSN = {26666510},
   DOI = {10.1016/j.aiopen.2021.01.001},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{RN147,
   author = {He, Ruining and Ravula, Anirudh and Kanagal, Bhargav and Ainslie, Joshua},
   title = {RealFormer: Transformer Likes Residual Attention},
   booktitle = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2021.findings-acl.81},
   type = {Conference Proceedings}
}

@inproceedings{RN131,
   author = {Li, Ronghan and Wang, Lifang and Wang, Shengli and Jiang, Zejun},
   title = {Asynchronous Multi-grained Graph Network For Interpretable Multi-hop Reading Comprehension},
   year = {2021},
   booktitle = {Proceedings of the Thirtieth International Joint Conference on Artificial Intelligence},
   publisher = {International Joint Conferences on Artificial Intelligence Organization},
   DOI = {10.24963/ijcai.2021/531},
   type = {Conference Proceedings}
}

@article{RN149,
   author = {Li, Shaobo and Li, Xiaoguang and Shang, Lifeng and Jiang, Xin and Liu, Qun and Sun, Chengjie and Ji, Zhenzhou and Liu, Bingquan},
   title = {HopRetriever: Retrieve Hops over Wikipedia to Answer Complex Questions},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {35},
   number = {15},
   pages = {13279-13287},
   ISSN = {2374-3468},
   DOI = {10.1609/aaai.v35i15.17568},
   year = {2021},
   type = {Journal Article}
}

@article{RN94,
   author = {Liao, Jinzhi and Zhao, Xiang and Li, Xinyi and Tang, Jiuyang and Ge, Bin},
   title = {Contrastive heterogeneous graphs learning for multi-hop machine reading comprehension},
   journal = {World Wide Web},
   volume = {25},
   number = {3},
   pages = {1469-1487},
   ISSN = {1386-145X
1573-1413},
   DOI = {10.1007/s11280-021-00980-6},
   year = {2021},
   type = {Journal Article}
}

@inproceedings{RN133,
   author = {Shi, Jiaxin and Cao, Shulin and Hou, Lei and Li, Juanzi and Zhang, Hanwang},
   title = {TransferNet: An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph},
   booktitle = {Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing},
   publisher = {Association for Computational Linguistics},
   year = {2021},
   pages = {4149-4158},
   DOI = {10.18653/v1/2021.emnlp-main.341},
   type = {Conference Proceedings}
}

@article{RN106,
   author = {Wu, Bohong and Zhang, Zhuosheng and Zhao, Hai},
   title = {Graph-free Multi-hop Reading Comprehension: A Select-to-Guide Strategy},
   year = {2021},
   type = {Journal Article}
}

@article{RN16,
   author = {Wu, Z. and Pan, S. and Chen, F. and Long, G. and Zhang, C. and Yu, P. S.},
   title = {A Comprehensive Survey on Graph Neural Networks},
   journal = {IEEE Trans Neural Netw Learn Syst},
   volume = {32},
   number = {1},
   pages = {4-24},
   note = {Wu, Zonghan
Pan, Shirui
Chen, Fengwen
Long, Guodong
Zhang, Chengqi
Yu, Philip S
eng
Research Support, Non-U.S. Gov't
Review
2020/03/29
IEEE Trans Neural Netw Learn Syst. 2021 Jan;32(1):4-24. doi: 10.1109/TNNLS.2020.2978386. Epub 2021 Jan 4.},
   abstract = {Deep learning has revolutionized many machine learning tasks in recent years, ranging from image classification and video processing to speech recognition and natural language understanding. The data in these tasks are typically represented in the Euclidean space. However, there is an increasing number of applications, where data are generated from non-Euclidean domains and are represented as graphs with complex relationships and interdependency between objects. The complexity of graph data has imposed significant challenges on the existing machine learning algorithms. Recently, many studies on extending deep learning approaches for graph data have emerged. In this article, we provide a comprehensive overview of graph neural networks (GNNs) in data mining and machine learning fields. We propose a new taxonomy to divide the state-of-the-art GNNs into four categories, namely, recurrent GNNs, convolutional GNNs, graph autoencoders, and spatial-temporal GNNs. We further discuss the applications of GNNs across various domains and summarize the open-source codes, benchmark data sets, and model evaluation of GNNs. Finally, we propose potential research directions in this rapidly growing field.},
   keywords = {Algorithms
Data Mining
Humans
Machine Learning
*Neural Networks, Computer
Surveys and Questionnaires},
   ISSN = {2162-2388 (Electronic)
2162-237X (Linking)},
   DOI = {10.1109/TNNLS.2020.2978386},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/32217482},
   year = {2021},
   type = {Journal Article}
}

@article{RN151,
   author = {Hou, Xia and Luo, Jintao and Li, Junzhe and Wang, Liangguo and Yang, Hongbo},
   title = {A Novel Knowledge Base Question Answering Method Based on Graph Convolutional Network and Optimized Search Space},
   journal = {Electronics},
   volume = {11},
   number = {23},
   pages = {3897},
   ISSN = {2079-9292},
   DOI = {10.3390/electronics11233897},
   year = {2022},
   type = {Journal Article}
}

@article{RN80,
   author = {Mohammadi, Azade and Ramezani, Reza and Baraani, Ahmad},
   title = {A Comprehensive Survey on Multi-hop Machine Reading Comprehension Approaches},
   year = {2022},
   type = {Journal Article}
}

@article{RN111,
   author = {Song, L. and Wang, Z. and Yu, M. and Zhang, Y. and Florian, R. and Gildea, D.},
   title = {Evidence Integration for Multi-Hop Reading Comprehension With Graph Neural Networks},
   journal = {IEEE Transactions on Knowledge and Data Engineering},
   volume = {34},
   number = {2},
   pages = {631-639},
   ISSN = {1558-2191},
   DOI = {10.1109/TKDE.2020.2982894},
   year = {2022},
   type = {Journal Article}
}

@article{RN100,
   author = {Staliunaite, Ieva and Gorinski, P. and Iacobacci, Ignacio},
   title = {Relational Graph Convolutional Neural Networks for Multihop Reasoning: A Comparative Study},
   year = {2022},
   type = {Journal Article}
}

@article{RN143,
   author = {Tang, Jiuyang and Hu, Shengze and Chen, Ziyang and Xu, Hao and Tan, Zhen},
   title = {Incorporating Phrases in Latent Query Reformulation for Multi-Hop Question Answering},
   journal = {Mathematics},
   volume = {10},
   number = {4},
   pages = {646},
   ISSN = {2227-7390},
   DOI = {10.3390/math10040646},
   year = {2022},
   type = {Journal Article}
}

@article{RN23,
   author = {Wu, Lingfei and Chen, Yu and Shen, Kai and Guo, Xiaojie and Gao, Hanning and Li, Shucheng and Pei, Jian and Long, Bo},
   title = {Graph Neural Networks for Natural Language Processing: A Survey},
   journal = {arXiv},
   year = {2022},
   type = {Journal Article}
}

@book{RN35,
   author = {Wu, Lingfei and Cui, Peng and Pei, Jian and Zhao, Liang},
   title = {Graph Neural Networks: Foundations, Frontiers, and Applications},
   year = {2022},
   type = {Book}
}

@inproceedings{RN134,
   author = {Ye, Xi and Yavuz, Semih and Hashimoto, Kazuma and Zhou, Yingbo and Xiong, Caiming},
   title = {RNG-KBQA: Generation Augmented Iterative Ranking for Knowledge Base Question Answering},
   booktitle = {Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2022.acl-long.417},
   type = {Conference Proceedings}
}

@article{RN95,
   author = {Zhang, Y. and Jin, L. and Li, X. and Wang, H.},
   title = {Edge-Aware Graph Neural Network for Multi-Hop Path Reasoning over Knowledge Base},
   journal = {Comput Intell Neurosci},
   volume = {2022},
   pages = {4734179},
   note = {Zhang, Yanan
Jin, Li
Li, Xiaoyu
Wang, Honqi
eng
2022/10/25
Comput Intell Neurosci. 2022 Oct 12;2022:4734179. doi: 10.1155/2022/4734179. eCollection 2022.},
   abstract = {Multi-hop path reasoning over knowledge base aims at finding answer entities for an input question by walking along a path of triples from graph structure data, which is a crucial branch in the knowledge base question answering (KBQA) research field. Previous studies rely on deep neural networks to simulate the way humans solve multi-hop questions, which do not consider the latent relation information contained in connected edges, and lack of measuring the correlation between specific relations and the input question. To address these challenges, we propose an edge-aware graph neural network for multi-hop path reasoning task. First, a query node is directly added to the candidate subgraph retrieved from the knowledge base, which constructs what we term a query graph. This graph construction strategy makes it possible to enhance the information flow between the question and the nodes for the subsequent message passing steps. Second, question-related information contained in the relations is added to the entity node representations during graph updating; meanwhile, the relation representations are updated. Finally, the attention mechanism is used to weight the contribution from neighbor nodes so that only the information of neighbor nodes related to the query can be injected into new node representations. Experimental results on MetaQA and PathQuestion-Large (PQL) benchmarks demonstrate that the proposed model achieves higher Hit@1 and F1 scores than the baseline methods by a large margin. Moreover, ablation studies show that both the graph construction and the graph update algorithm contribute to performance improvement.},
   keywords = {Humans
*Neural Networks, Computer
*Knowledge Bases
Algorithms},
   ISSN = {1687-5273 (Electronic)
1687-5265 (Print)},
   DOI = {10.1155/2022/4734179},
   url = {https://www.ncbi.nlm.nih.gov/pubmed/36275972},
   year = {2022},
   type = {Journal Article}
}

@article{RN144,
   author = {Zhang, Ying and Meng, Fandong and Zhang, Jinchao and Chen, Yufeng and Xu, Jinan and Zhou, Jie},
   title = {MKGN: A Multi-Dimensional Knowledge Enhanced Graph Network for Multi-Hop Question and Answering},
   journal = {IEICE Transactions on Information and Systems},
   volume = {E105.D},
   number = {4},
   pages = {807-819},
   ISSN = {0916-8532},
   DOI = {10.1587/transinf.2021edp7154},
   year = {2022},
   type = {Journal Article}
}

@article{RN136,
   author = {Gao, Peng and Gao, Feng and Wang, Peng and Ni, Jian-Cheng and Wang, Fei and Fujita, Hamido},
   title = {ClueReader: Heterogeneous Graph Attention Network for Multi-Hop Machine Reading Comprehension},
   journal = {Electronics},
   volume = {12},
   number = {14},
   pages = {3183},
   ISSN = {2079-9292},
   DOI = {10.3390/electronics12143183},
   year = {2023},
   type = {Journal Article}
}

@misc{RN109,
   author = {Yang, Ni and Yang, Meng},
   title = {Multi-hop Attention GNN with Answer-Evidence Contrastive Loss for Multi-hop QA},
   pages = {1-7},
   DOI = {10.1109/ijcnn54540.2023.10191117},
   year = {2023},
   type = {Conference Paper}
}

@inbook{RN108,
   author = {Yin, Zhangyue and Wang, Yuxin and Hu, Xiannian and Wu, Yiguang and Yan, Hang and Zhang, Xinyu and Cao, Zhao and Huang, Xuanjing and Qiu, Xipeng},
   title = {Rethinking Label Smoothing on Multi-Hop Question Answering},
   booktitle = {Lecture Notes in Computer Science},
   publisher = {Springer Nature Singapore},
   pages = {72-87},
   ISBN = {0302-9743},
   DOI = {10.1007/978-981-99-6207-5_5},
   year = {2023},
   type = {Book Section}
}

@article{RN105,
   author = {Zhang, Jiahao and Zhang, Haiyang and Zhang, Dongmei and Liu, Yong and Huang, Shen},
   title = {Beam Retrieval: General End-to-End Retrieval for Multi-Hop Question Answering},
   year = {2023},
   type = {Journal Article}
}

@inproceedings{RN152,
   author = {Khashabi, Daniel and Chaturvedi, Snigdha and Roth, Michael and Upadhyay, Shyam and Roth, Dan},
   title = {Looking Beyond the Surface: A Challenge Set for Reading
            Comprehension over Multiple Sentences},
   year = {2018},
   booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
          the Association for Computational Linguistics: Human Language
          Technologies, Volume 1 (Long Papers)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/n18-1023},
   type = {Conference Proceedings}
}

@inproceedings{RN153,
   author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
   title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
   year = {2019},
   booktitle = {Proceedings of the 2019 Conference of the North},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/n19-1423},
   type = {Conference Proceedings}
}

@inproceedings{RN156,
   author = {Fu, Ruiliu and Wang, Han and Zhang, Xuejun and Zhou, Jun and Yan, Yonghong},
   title = {Decomposing Complex Questions Makes Multi-Hop QA Easier and More Interpretable},
   year = {2021},
   booktitle = {Findings of the Association for Computational Linguistics: EMNLP 2021},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2021.findings-emnlp.17},
   type = {Conference Proceedings}
}

@inproceedings{RN169,
   author = {Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
   title = {Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected Reasoning},
   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.emnlp-main.712},
   year = {2020},
   type = {Conference Proceedings}
}

@inproceedings{RN168,
   author = {Li, Xin-Yi and Lei, Wei-Jun and Yang, Yu-Bin},
   title = {From Easy to Hard: Two-Stage Selector and Reader for Multi-Hop Question Answering},
   booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher = {IEEE},
   DOI = {10.1109/icassp49357.2023.10096119},
   year = {2023},
   type = {Conference Proceedings}
}

@article{RN167,
   author = {Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
   title = {MuSiQue: Multihop Questions via Single-hop Question Composition},
   journal = {Transactions of the Association for Computational Linguistics},
   volume = {10},
   pages = {539-554},
   ISSN = {2307-387X},
   DOI = {10.1162/tacl_a_00475},
   year = {2022},
   type = {Journal Article}
}

@article{RN166,
   author = {Zhu, Fengbin and Lei, Wenqiang and Wang, Chao and Zheng, Jianming and Poria, Soujanya and Chua, Tat-Seng},
   title = {Retrieving and Reading: A Comprehensive Survey on Open-domain Question Answering},
   journal = {CoRR},
   volume = {abs/2101.00774},
   url = {https://arxiv.org/abs/2101.00774},
   year = {2021},
   type = {Journal Article}
}

@article{RN165,
   author = {Mavi, Vaibhav and Jangra, Anubhav and Jatowt, A.},
   title = {A Survey on Multi-hop Question Answering and Generation},
   journal = {arXiv},
   ISSN = {0360-0300
1557-7341},
   DOI = {10.1145/1122445.1122456},
   year = {2022},
   type = {Journal Article}
}

@article{RN164,
   author = {Daull, Xavier and Bellot, P. and Bruno, Emmanuel and Martin, Vincent and Murisasco, Elisabeth},
   title = {Complex QA and language models hybrid architectures, Survey},
   journal = {arXiv},
   url = {https://api.semanticscholar.org/CorpusID:257019916},
   year = {2023},
   type = {Journal Article}
}

@inproceedings{RN163,
   author = {Tang, Yixuan and Ng, Hwee Tou and Tung, Anthony},
   title = {Do Multi-Hop Question Answering Systems Know How to Answer the Single-Hop Sub-Questions?},
   booktitle = {Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2021.eacl-main.283},
   year = {2021},
   type = {Conference Proceedings}
}

@inproceedings{RN162,
   author = {Jiang, Yichen and Joshi, Nitish and Chen, Yen-Chun and Bansal, Mohit},
   title = {Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1261},
   year = {2019},
   type = {Conference Proceedings}
}

@article{RN161,
   author = {Bhargav, G P Shrivatsa and Glass, Michael and Garg, Dinesh and Shevade, Shirish and Dana, Saswati and Khandelwal, Dinesh and Subramaniam, L Venkata and Gliozzo, Alfio},
   title = {Translucent Answer Predictions in Multi-Hop Reading Comprehension},
   journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
   volume = {34},
   number = {05},
   pages = {7700-7707},
   ISSN = {2374-3468},
   DOI = {10.1609/aaai.v34i05.6272},
   year = {2020},
   type = {Journal Article}
}

@inproceedings{RN160,
   author = {Nishida, Kosuke and Nishida, Kyosuke and Nagata, Masaaki and Otsuka, Atsushi and Saito, Itsumi and Asano, Hisako and Tomita, Junji},
   title = {Answering while Summarizing: Multi-task Learning for Multi-hop QA with Evidence Extraction},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1225},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{RN159,
   author = {Bauer, Lisa and Wang, Yicheng and Bansal, Mohit},
   title = {Commonsense for Generative Multi-Hop Question Answering Tasks},
   booktitle = {Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/d18-1454},
   year = {2018},
   type = {Conference Proceedings}
}

@article{RN158,
   author = {Cao, Xing and Liu, Yun},
   title = {Coarse-grained decomposition and fine-grained interaction for multi-hop question answering},
   journal = {Journal of Intelligent Information Systems},
   volume = {58},
   number = {1},
   pages = {21-41},
   ISSN = {0925-9902},
   DOI = {10.1007/s10844-021-00645-w},
   year = {2022},
   type = {Journal Article}
}

@inproceedings{RN157,
   author = {Perez, Ethan and Lewis, Patrick and Yih, Wen-Tau and Cho, Kyunghyun and Kiela, Douwe},
   title = {Unsupervised Question Decomposition for Question Answering},
   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.emnlp-main.713},
   year = {2020},
   type = {Conference Proceedings}
}

@inproceedings{RN170,
   author = {Manning, Christopher and Surdeanu, Mihai and Bauer, John and Finkel, Jenny and Bethard, Steven and Mcclosky, David},
   title = {The Stanford CoreNLP Natural Language Processing Toolkit},
   booktitle = {Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations},
   publisher = {Association for Computational Linguistics},
   DOI = {10.3115/v1/p14-5010},
   year = {2014},
   type = {Conference Proceedings}
}

@article{RN171,
   author = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
   title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
   journal = {arXiv preprint},
   DOI = {arXiv:1907.11692},
   year = {2019},
   type = {Journal Article}
}

@inproceedings{RN176,
   author = {Jiang, Yichen and Bansal, Mohit},
   title = {Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training, and Model Development for Multi-Hop QA},
   booktitle = {Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/p19-1262},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{RN175,
   author = {Trivedi, Harsh and Balasubramanian, Niranjan and Khot, Tushar and Sabharwal, Ashish},
   title = {Is Multihop QA in DiRe Condition? Measuring and Reducing Disconnected Reasoning},
   booktitle = {Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2020.emnlp-main.712},
   year = {2020},
   type = {Conference Proceedings}
}

@inproceedings{RN154,
   author = {Chen, Jifan and Durrett, Greg},
   title = {Understanding Dataset Design Choices for Multi-hop Reasoning},
   booktitle = {Proceedings of the 2019 Conference of the North},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/n19-1405},
   year = {2019},
   type = {Conference Proceedings}
}

@inproceedings{RN177,
   author = {Ho, Xanh and Duong Nguyen, Anh-Khoa and Sugawara, Saku and Aizawa, Akiko},
   title = {Analyzing the Effectiveness of the Underlying Reasoning Tasks in Multi-hop Question Answering},
   booktitle = {Findings of the Association for Computational Linguistics: EACL 2023},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/2023.findings-eacl.87},
   year = {2023},
   type = {Conference Proceedings}
}




@InProceedings{RN173,
author="Xu, Liang
and Yao, Junjie
and Zhang, Yingjie",
editor="Wang, Xin
and Zhang, Rui
and Lee, Young-Koo
and Sun, Le
and Moon, Yang-Sae",
title="Dynamic Multi-hop Reasoning",
booktitle="Web and Big Data",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="535--543",
abstract="Multi-hop reasoning is an essential part of the current reading comprehension and question answering areas. The reasoning methods have been extensively studied, and most of them are generally focused on the pre-retrieval based inference, with the help of a few paragraphs. These methods are fixed and unable to cope with dynamic and complex questions. Here, we propose to utilize the dynamic graph reasoning network for multi-hop reading comprehension question answering.",
isbn="978-3-030-60259-8"
}



@article{RN171b,
title = {Keywords-aware dynamic graph neural network for multi-hop reading comprehension},
journal = {Neurocomputing},
volume = {501},
pages = {25-40},
year = {2022},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2022.05.110},
url = {https://www.sciencedirect.com/science/article/pii/S0925231222006932},
author = {Meihuizi Jia and Lejian Liao and Wenjing Wang and Fei Li and Zhendong Chen and Jiaqi Li and Heyan Huang},
keywords = {Multi-hop reading comprehension, Graph neural network, Dynamic reasoning graph},
abstract = {The multi-hop reading comprehension (RC) is challenging for machine reading comprehension. It is crucial for multi-hop RC to comprehend complex questions and contents between multiple paragraphs. In this paper, we propose a strategy of keywords-aware dynamic graph neural network (KA-DGN) to improve the performance of multi-hop reading comprehension. First of all, KA-DGN focuses on the salient information in the text, extracts keywords from the question and context. A window is specifically designed to frame the interrogative pronoun/adverb and its nearby words in the question, which encourages the model to focus on the answer. Next, the token-level answer span is predicted under the guidance of the keywords. And the boundary loss function is also invented to enhance the boundary awareness of the model on extracting the answer, which maximizes the probability of answer span bound while minimizing that of the noise. Finally, the model builds a dynamic reasoning graph combining explicit keywords and implicit semantic information among sentences. Graph neural network is applied to predict the sentence-level supporting facts. While evaluating on HotpotQA, the proposed KA-DGN achieves competitive performance in distractor setting.}
}
@inproceedings{RN202,
    title = {Exploring Content Models for Multi-Document Summarization},
    author = {Haghighi, Aria and Vanderwende, Lucy},
    booktitle = {Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
    year = {2009},
    address = {Boulder, Colorado},
    publisher = {Association for Computational Linguistics},
    pages = {362--370},
}

@InProceedings{RN172,
author="Tang, Xiu
and Xu, Yangchao
and Lu, Xuefeng
and He, Qiang
and Fang, Jun
and Chen, Junjie",
editor="Chen, Weitong
and Yao, Lina
and Cai, Taotao
and Pan, Shirui
and Shen, Tao
and Li, Xue",
title="DeMRC: Dynamically Enhanced Multi-hop Reading Comprehension Model for Low Data",
booktitle="Advanced Data Mining and Applications",
year="2022",
publisher="Springer Nature Switzerland",
address="Cham",
pages="43--57",
abstract="Multi-hop reading comprehension requires the aggregation of multiple evidence facts to answer complex natural language questions, and the answer should be avoided when there is no answer. Training a model that can handle such difficult tasks requires a large number of data sets to support, but the labeling of data sets is very expensive and time-consuming, so it is very important to explore reading comprehension models suitable for low data, and external data related to large-scale tasks. It will also effectively improve the performance of the model. This paper proposes a two-stage model with dynamically context-enhanced method for multi-hop reading comprehension tasks under low data called DeMRC. The first stage sentence filtering model filters the top k sentences that are strongly related to the question, and the second stage answer prediction model dynamically constructs the training set every time during training to expand the data set, and uses sentences selected by sentence filtering model as input to reduce the interference of irrelevant sentences to the model during inference. In addition, the self-training method is used to pseudo-label the external data and use it as an auxiliary data set to improve the performance of the model. We conducted experiments on the multi-hop reading comprehension data set of the Chinese ``CAIL 2020`` Judicial Artificial Intelligence Challenge Reading Comprehension Track and English cross-document level data set called HotpotQA, which are 3.5{\%} and 21.3{\%} higher than the powerful baseline model, showing the effectiveness of the method.",
isbn="978-3-031-22137-8"
}

@INPROCEEDINGS{RN203,
  author={Gori, M. and Monfardini, G. and Scarselli, F.},
  booktitle={Proceedings. 2005 IEEE International Joint Conference on Neural Networks, 2005.}, 
  title={A new model for learning in graph domains}, 
  year={2005},
  volume={2},
  number={},
  pages={729-734 vol. 2},
  doi={10.1109/IJCNN.2005.1555942}}


@ARTICLE{RN204,
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE Transactions on Neural Networks}, 
  title={The Graph Neural Network Model}, 
  year={2009},
  volume={20},
  number={1},
  pages={61-80},
  doi={10.1109/TNN.2008.2005605}
}

@article{RN205,
   author = {Zhou, Jie and Cui, Ganqu and Hu, Shengding and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
   year = {2020},
   pages = {57-81},
   title = {Graph neural networks: A review of methods and applications},
   volume = {1},
   journal = {AI Open},
   doi = {10.1016/j.aiopen.2021.01.001}
}

@ARTICLE{RN206,
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S.},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Comprehensive Survey on Graph Neural Networks}, 
  year={2021},
  volume={32},
  number={1},
  pages={4-24},
  doi={10.1109/TNNLS.2020.2978386}
}

@article{RN207,
  title={Inductive representation learning on large graphs},
  author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{RN208,
author = {Chen, Danqi and Bolton, Jason and Manning, Christopher},
year = {2016},
month = {06},
pages = {2358-2367},
title = {A Thorough Examination of the CNN/Daily Mail Reading Comprehension Task},
doi = {10.18653/v1/P16-1223}
}

@article{RN210,
  title={Graph sequential network for reasoning over sequences},
  author={Tu, Ming and Huang, Jing and He, Xiaodong and Zhou, Bowen},
  journal={arXiv preprint arXiv:2004.02001},
  year={2020}
}

@inproceedings{RN201,
  title={Abstractive timeline summarization},
  author={Steen, Julius and Markert, Katja},
  booktitle={Proceedings of the 2nd Workshop on New Frontiers in Summarization},
  pages={21--31},
  year={2019}
}

@article{RN211,
  title={Relational inductive biases, deep learning, and graph networks},
  author={Battaglia, Peter W and Hamrick, Jessica B and Bapst, Victor and Sanchez-Gonzalez, Alvaro and Zambaldi, Vinicius and Malinowski, Mateusz and Tacchetti, Andrea and Raposo, David and Santoro, Adam and Faulkner, Ryan and others},
  journal={arXiv preprint arXiv:1806.01261},
  year={2018}
}

@article{RN213,
  title={GNNExplainer: Generating explanations for graph neural networks},
  author={Ying, Zhitao and Bourgeois, Dylan and You, Jiaxuan and Zitnik, Marinka and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{RN214,
  title={Assessing the benchmarking capacity of machine reading comprehension datasets},
  author={Sugawara, Saku and Stenetorp, Pontus and Inui, Kentaro and Aizawa, Akiko},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={8918--8927},
  year={2020}
}

@inproceedings{RN215,
 author = {Tang, Hao and Huang, Zhiao and Gu, Jiayuan and Lu, Bao-Liang and Su, Hao},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M.F. Balcan and H. Lin},
 pages = {15811--15822},
 publisher = {Curran Associates, Inc.},
 title = {Towards Scale-Invariant Graph-related Problem Solving by Iterative Homogeneous GNNs},
 url = {https://proceedings.neurips.cc/paper_files/paper/2020/file/b64a70760bb75e3ecfd1ad86d8f10c88-Paper.pdf},
 volume = {33},
 year = {2020}
}

@inproceedings{RN216,
 author = {Zhang, Hengrui and Yu, Zhongming and Dai, Guohao and Huang, Guyue and Ding, Yufei and Xie, Yuan and Wang, Yu},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {D. Marculescu and Y. Chi and C. Wu},
 pages = {467--484},
 title = {Understanding GNN Computational Graph: A Coordinated Computation, IO, and Memory Perspective},
 url = {https://proceedings.mlsys.org/paper_files/paper/2022/file/b559156047e50cf316207249d0b5a6c5-Paper.pdf},
 volume = {4},
 year = {2022}
}

@article{RN98,
   author = {Pennington, Jeffrey and Socher, R. and Manning, Christopher D.},
   title = {GloVe: Global Vectors for Word Representation},
   year = {2014},
   type = {Journal Article}
}

@inproceedings{RN183,
   author = {Peters, Matthew and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke},
   title = {Deep Contextualized Word Representations},
   booktitle = {Proceedings of the 2018 Conference of the North American Chapter of
          the Association for Computational Linguistics: Human Language
          Technologies, Volume 1 (Long Papers)},
   publisher = {Association for Computational Linguistics},
   DOI = {10.18653/v1/n18-1202},
   year = {2018},
   type = {Conference Proceedings}
}

@inproceedings{RN300,
    title = "{FEVER}: a Large-scale Dataset for Fact Extraction and {VER}ification",
    author = "Thorne, James  and
      Vlachos, Andreas  and
      Christodoulopoulos, Christos  and
      Mittal, Arpit",
    editor = "Walker, Marilyn  and
      Ji, Heng  and
      Stent, Amanda",
    booktitle = "Proceedings of the 2018 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)",
    month = jun,
    year = "2018",
    address = "New Orleans, Louisiana",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N18-1074",
    doi = "10.18653/v1/N18-1074",
    pages = "809--819",
    abstract = "In this paper we introduce a new publicly available dataset for verification against textual sources, FEVER: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87{\%}, while if we ignore the evidence we achieve 50.91{\%}. Thus we believe that FEVER is a challenging testbed that will help stimulate progress on claim verification against textual sources.",
}

@article{RN301,
  author       = {Chaojun Xiao and
                  Haoxi Zhong and
                  Zhipeng Guo and
                  Cunchao Tu and
                  Zhiyuan Liu and
                  Maosong Sun and
                  Yansong Feng and
                  Xianpei Han and
                  Zhen Hu and
                  Heng Wang and
                  Jianfeng Xu},
  title        = {{CAIL2018:} {A} Large-Scale Legal Dataset for Judgment Prediction},
  journal      = {CoRR},
  volume       = {abs/1807.02478},
  year         = {2018},
  url          = {http://arxiv.org/abs/1807.02478},
  eprinttype    = {arXiv},
  eprint       = {1807.02478},
  timestamp    = {Fri, 01 Sep 2023 13:50:21 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1807-02478.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}






