\documentclass[10pt]{beamer}

\usetheme[progressbar=frametitle]{metropolis}
\usepackage{appendixnumberbeamer}

\usepackage{booktabs}
\usepackage[scale=2]{ccicons}

\usepackage{pgfplots}
\usepgfplotslibrary{dateplot}

\usepackage{xspace}
\newcommand{\themename}{\textbf{\textsc{metropolis}}\xspace}


\title{A Survey of Multi-hop Reading Comprehension approaches using Graph Neural Networks}
\subtitle{Seminar Presentation}
% \date{\today}
\date{}

\author{Ajay Narayanan, Constantin Weberpals, Tim Bruckdorfer}

\institute{Technical University of Munich}
% \titlegraphic{\hfill\includegraphics[height=1.5cm]{logo.pdf}}

\begin{document}

\maketitle

\begin{frame}{Table of contents}
  \setbeamertemplate{section in toc}[sections numbered]
  \tableofcontents%[hideallsubsections]
\end{frame}

\section[Intro]{Introduction}

\begin{frame}[fragile]{What is Multi-hop Reading Comprehension?}

  % The \themename theme is a Beamer theme with minimal visual noise
  % inspired by the \href{https://github.com/hsrmbeamertheme/hsrmbeamertheme}{\textsc{hsrm} Beamer
  % Theme} by Benjamin Weiss.

  % Enable the theme by loading

  % \begin{verbatim}    \documentclass{beamer}
  %   \usetheme{metropolis}\end{verbatim}

  % Note, that you have to have Mozilla's \emph{Fira Sans} font and XeTeX
  % installed to enjoy this wonderful typography.
  \begin{itemize}
    \item Machine reading comprehension is a task in NLP where a machine is given a question and a passage of text and is expected to answer the question using the passage.
    \item For Multi-hop RC, There are multiple passages, and the questions are usually complex and require the machine to perform multiple steps of reasoning to arrive at the answer.
    
  \end{itemize}
\end{frame}

\begin{frame}
  \begin{figure}[t] % 'h' for "here", can be replaced with other placement specifiers
    \centering
    \includegraphics[width=\linewidth]{fig/fig_1_hotpot_example.pdf} % Adjust 'width' as needed
    \caption{A Sample question from the HotpotQA dataset}
    \label{fig:sample_hotpotqa} % For referencing the figure in the text
  \end{figure}
\end{frame}

\begin{frame}[fragile]{What is Multi-hop Reading Comprehension?}

  \begin{itemize}
    \item The task is usually split into two parts: finding the relevant parts of the passage and then using those parts to answer the question.
    \item The task is usually evaluated using the F1 score, which is the harmonic mean of precision and recall.
    
  \end{itemize}
\end{frame}


\begin{frame}[fragile]{Sections}
  Sections group slides of the same topic

  \begin{verbatim}    \section{Elements}\end{verbatim}

  for which \themename provides a nice progress indicator \ldots
  
\end{frame}

\section{Theoretical Background}

\subsection{Machine Reading Comprehension (MRC)}

\begin{frame}{Machine Reading Comprehension (MRC)}
  \begin{itemize}
    \item MRC: A key NLP task where machines answer questions using text passages.
    \item Requires advanced NLP techniques: semantic analysis, context understanding, language modeling.
    \item Challenges: Deep text understanding, context inference, mimicking human comprehension.
  \end{itemize}
\end{frame}

\subsection{Multi-hop Reading Comprehension}

\begin{frame}{Multi-hop Reading Comprehension}
  \begin{itemize}
    \item Multi-hop RC: Involves complex questions requiring reasoning over multiple texts.
    \item Key skill: Connecting disparate pieces of information to answer questions.
    \item Applications: Document summarization, complex query answering.
  \end{itemize}
\end{frame}

\subsection{Graph Neural Networks in MHRC}

\begin{frame}{Graph Neural Networks in MHRC}
  \begin{itemize}
    \item GNNs: Handle graph-structured data, capturing complex relationships.
    \item Key features: Node representation, neighborhood aggregation, iterative learning.
    \item GNN Variants: GCNs (Kipf and Welling, 2016) and GATs (Veličković et al., 2018).
    \item Application in MHRC: Effective in multi-hop reasoning, information aggregation.
  \end{itemize}
\end{frame}

\subsection{Importance of Datasets}

\begin{frame}{Importance of Datasets in MHRC}
  \begin{itemize}
    \item Critical Datasets: HotpotQA, WikiHop, ComplexWebQuestions.
    \item Role: Benchmarking performance, challenging reasoning capabilities.
    \item Limitation: Often lack diversity and real-world complexity.
  \end{itemize}
\end{frame}



\section{Core Concepts}

\subsection{Graph based approach: HGN}

\begin{frame}
  \frametitle{Hierarchical Graph Network}

  \begin{figure}[t] % 'h' for "here", can be replaced with other placement specifiers
    \centering
    \includegraphics[width=\linewidth]{fig/ext_fig/hgn_diagram.png} % Adjust 'width' as needed
    \caption{Model architecture for HGN, figure taken from \cite{RN119}}
    \label{fig:sample_hotpotqa} % For referencing the figure in the text
  \end{figure}

\end{frame}

\subsection{Non-Graph based approach: S2G}

\begin{frame}
  \frametitle{Select-to-Guide Strategy}

  \begin{figure}[t] % 'h' for "here", can be replaced with other placement specifiers
    \centering
    \includegraphics[width=\linewidth]{fig/ext_fig/s2g_diagram.png} % Adjust 'width' as needed
    \caption{Model architecture for S2G, figure taken from \cite{RN106}}
    \label{fig:sample_hotpotqa} % For referencing the figure in the text
  \end{figure}

\end{frame}

\subsection{Arguments against Graph-based approaches}

\begin{frame}
  \frametitle{Arguments against Graph-based approaches}
  \begin{itemize}
    \item \textbf{Shao et al. (2020)} \cite{RN127} argue that with the proper use of pre-trained models, graph structure may not be necessary.
    \item They also point out that adjacency matrix and graph structure can be regarded as task-related prior knowledge.
    \item \textbf{Groeneveld et al. (2020)} \cite{RN126} showed that a simple BERT based model can outperform a Graph-based model on the HotpotQA dataset.
  \end{itemize}

\end{frame}

\begin{frame}
  \frametitle{Arguments against Graph-based approaches}
  \begin{itemize}
    \item \textbf{Wu et al. (2021)} \cite{RN106} highlights limitations of graph modeling for MHRC, which requires NER and also rigid rule-based graph construction.
    \item They also point out that the retrieval stage might be more important than the reasoning stage.
  \end{itemize}

\end{frame}

\subsection{Dataset Limitations}

\begin{frame}
  \frametitle{Dataset Limitations}
  \begin{itemize}
    \item \textbf{Min et al. (2019)} \cite{RN150} argue that constructing large multihop datasets is difficult, and that the current datasets like HotpotQA can be solved with single-hop approaches.
    \item They noted that humans could solve over 80\% of HotpotQA questions with one gold paragraph withheld.
    \item \textbf{Groenveld et al. (2020)} indicate that HotpotQA might not be suitable to demonstrate the value of more complex retrieval techniques, and that supporting sentence identification in HotpotQA might not be a multi-hop problem at all.
  \end{itemize}
  
\end{frame}

\begin{frame}
  \frametitle{Dataset Limitations}
  \begin{itemize}
    \item Several studies \cite{RN154} \cite{RN176} \cite{RN150} \cite{RN175} indicate that many questions in HotpotQA can be answered using heuristics, 
    as they have biases and reasoning shortcuts \cite{RN177}.
  \end{itemize}
  
\end{frame}

% \begin{frame}[fragile]{Typography}
%       \begin{verbatim}The theme provides sensible defaults to
% \emph{emphasize} text, \alert{accent} parts
% or show \textbf{bold} results.\end{verbatim}

%   \begin{center}becomes\end{center}

%   The theme provides sensible defaults to \emph{emphasize} text,
%   \alert{accent} parts or show \textbf{bold} results.
% \end{frame}

% \begin{frame}{Font feature test}
%   \begin{itemize}
%     \item Regular
%     \item \textit{Italic}
%     \item \textsc{SmallCaps}
%     \item \textbf{Bold}
%     \item \textbf{\textit{Bold Italic}}
%     \item \textbf{\textsc{Bold SmallCaps}}
%     \item \texttt{Monospace}
%     \item \texttt{\textit{Monospace Italic}}
%     \item \texttt{\textbf{Monospace Bold}}
%     \item \texttt{\textbf{\textit{Monospace Bold Italic}}}
%   \end{itemize}
% \end{frame}

% \begin{frame}{Lists}
%   \begin{columns}[T,onlytextwidth]
%     \column{0.33\textwidth}
%       Items
%       \begin{itemize}
%         \item Milk \item Eggs \item Potatos
%       \end{itemize}

%     \column{0.33\textwidth}
%       Enumerations
%       \begin{enumerate}
%         \item First, \item Second and \item Last.
%       \end{enumerate}

%     \column{0.33\textwidth}
%       Descriptions
%       \begin{description}
%         \item[PowerPoint] Meeh. \item[Beamer] Yeeeha.
%       \end{description}
%   \end{columns}
% \end{frame}
% \begin{frame}{Animation}
%   \begin{itemize}[<+- | alert@+>]
%     \item \alert<4>{This is\only<4>{ really} important}
%     \item Now this
%     \item And now this
%   \end{itemize}
% \end{frame}
% \begin{frame}{Figures}
%   \begin{figure}
%     \newcounter{density}
%     \setcounter{density}{20}
%     \begin{tikzpicture}
%       \def\couleur{alerted text.fg}
%       \path[coordinate] (0,0)  coordinate(A)
%                   ++( 90:5cm) coordinate(B)
%                   ++(0:5cm) coordinate(C)
%                   ++(-90:5cm) coordinate(D);
%       \draw[fill=\couleur!\thedensity] (A) -- (B) -- (C) --(D) -- cycle;
%       \foreach \x in {1,...,40}{%
%           \pgfmathsetcounter{density}{\thedensity+20}
%           \setcounter{density}{\thedensity}
%           \path[coordinate] coordinate(X) at (A){};
%           \path[coordinate] (A) -- (B) coordinate[pos=.10](A)
%                               -- (C) coordinate[pos=.10](B)
%                               -- (D) coordinate[pos=.10](C)
%                               -- (X) coordinate[pos=.10](D);
%           \draw[fill=\couleur!\thedensity] (A)--(B)--(C)-- (D) -- cycle;
%       }
%     \end{tikzpicture}
%     \caption{Rotated square from
%     \href{http://www.texample.net/tikz/examples/rotated-polygons/}{texample.net}.}
%   \end{figure}
% \end{frame}
% \begin{frame}{Tables}
%   \begin{table}
%     \caption{Largest cities in the world (source: Wikipedia)}
%     \begin{tabular}{lr}
%       \toprule
%       City & Population\\
%       \midrule
%       Mexico City & 20,116,842\\
%       Shanghai & 19,210,000\\
%       Peking & 15,796,450\\
%       Istanbul & 14,160,467\\
%       \bottomrule
%     \end{tabular}
%   \end{table}
% \end{frame}
% \begin{frame}{Blocks}
%   Three different block environments are pre-defined and may be styled with an
%   optional background color.

%   \begin{columns}[T,onlytextwidth]
%     \column{0.5\textwidth}
%       \begin{block}{Default}
%         Block content.
%       \end{block}

%       \begin{alertblock}{Alert}
%         Block content.
%       \end{alertblock}

%       \begin{exampleblock}{Example}
%         Block content.
%       \end{exampleblock}

%     \column{0.5\textwidth}

%       \metroset{block=fill}

%       \begin{block}{Default}
%         Block content.
%       \end{block}

%       \begin{alertblock}{Alert}
%         Block content.
%       \end{alertblock}

%       \begin{exampleblock}{Example}
%         Block content.
%       \end{exampleblock}

%   \end{columns}
% \end{frame}
% \begin{frame}{Math}
%   \begin{equation*}
%     e = \lim_{n\to \infty} \left(1 + \frac{1}{n}\right)^n
%   \end{equation*}
% \end{frame}
% \begin{frame}{Line plots}
%   \begin{figure}
%     \begin{tikzpicture}
%       \begin{axis}[
%         mlineplot,
%         width=0.9\textwidth,
%         height=6cm,
%       ]

%         \addplot {sin(deg(x))};
%         \addplot+[samples=100] {sin(deg(2*x))};

%       \end{axis}
%     \end{tikzpicture}
%   \end{figure}
% \end{frame}
% \begin{frame}{Bar charts}
%   \begin{figure}
%     \begin{tikzpicture}
%       \begin{axis}[
%         mbarplot,
%         xlabel={Foo},
%         ylabel={Bar},
%         width=0.9\textwidth,
%         height=6cm,
%       ]

%       \addplot plot coordinates {(1, 20) (2, 25) (3, 22.4) (4, 12.4)};
%       \addplot plot coordinates {(1, 18) (2, 24) (3, 23.5) (4, 13.2)};
%       \addplot plot coordinates {(1, 10) (2, 19) (3, 25) (4, 15.2)};

%       \legend{lorem, ipsum, dolor}

%       \end{axis}
%     \end{tikzpicture}
%   \end{figure}
% \end{frame}
% \begin{frame}{Quotes}
%   \begin{quote}
%     Veni, Vidi, Vici
%   \end{quote}
% \end{frame}

% {%
% \setbeamertemplate{frame footer}{My custom footer}
% \begin{frame}[fragile]{Frame footer}
%     \themename defines a custom beamer template to add a text to the footer. It can be set via
%     \begin{verbatim}\setbeamertemplate{frame footer}{My custom footer}\end{verbatim}
% \end{frame}
% }

% \begin{frame}{References}
%   Some references to showcase [allowframebreaks] \cite{RN2}
% \end{frame}

\section{Future Directions and Conclusion}

\subsection{Dataset Development}

\begin{frame}{Dataset Development}
  \begin{itemize}
    \item Future datasets should mirror real-world complexity.
    \item Aim: Enhance model robustness and adaptability.
    \item Focus: Diversity in scenarios, question types, and complexity.
  \end{itemize}
\end{frame}

\subsection{Model Efficiency and Generalization}

\begin{frame}{Model Efficiency and Generalization}
  \begin{itemize}
    \item Addressing computational resource requirements of GNNs.
    \item Cross-domain generalization: Adapting models for varied applications.
    \item Hybrid Models: Combining strengths of different GNN architectures.
  \end{itemize}
\end{frame}

\subsection{Ethical and Explainable AI}

\begin{frame}{Ethical and Explainable AI}
  \begin{itemize}
    \item Importance of transparent decision-making processes.
    \item Addressing ethical concerns in model deployment.
    \item Research focus: Making MHRC models more interpretable.
  \end{itemize}
\end{frame}

\subsection{Conclusion}

\begin{frame}{Conclusion}
  \begin{itemize}
    \item GNNs have significantly advanced MHRC by modeling complex textual relationships.
    \item Challenges remain in dataset quality, model scalability, and explainability.
    \item Future research should focus on creating diverse datasets, enhancing model efficiency, and ensuring ethical AI practices.
    \item The synergy between cognitive science and GNNs could pave the way for more intuitive and effective MHRC models.
  \end{itemize}
\end{frame}




\begin{frame}{Summary}

  Get the source of this theme and the demo presentation from

  \begin{center}\url{github.com/matze/mtheme}\end{center}

  The theme \emph{itself} is licensed under a
  \href{http://creativecommons.org/licenses/by-sa/4.0/}{Creative Commons
  Attribution-ShareAlike 4.0 International License}.

  \begin{center}\ccbysa\end{center}

\end{frame}

{\setbeamercolor{palette primary}{fg=black, bg=yellow}
\begin{frame}[standout]
  Questions?
\end{frame}
}

\appendix

\begin{frame}[fragile]{Backup slides}
  Sometimes, it is useful to add slides at the end of your presentation to
  refer to during audience questions.

  The best way to do this is to include the \verb|appendixnumberbeamer|
  package in your preamble and call \verb|\appendix| before your backup slides.

  \themename will automatically turn off slide numbering and progress bars for
  slides in the appendix.
\end{frame}

\begin{frame}[allowframebreaks]{References}

  \bibliography{bib.bib}
  \bibliographystyle{abbrv}

\end{frame}

\end{document}
